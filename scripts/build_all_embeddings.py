#!/usr/bin/env python3
"""æ–¹æ¡ˆ C: å…¨é‡å‘é‡åŒ– - å¤šç²’åº¦ Embedding ç”Ÿæˆ.

This script is intentionally thin; heavy logic lives in `_build_all_embeddings_lib.py`
to keep files under the 500 LOC limit.
"""

from __future__ import annotations

import sys
import time

import psycopg
from pgvector.psycopg import register_vector

from bid_scoring.config import load_settings
from bid_scoring.embeddings import get_embedding_client, get_embedding_config

from _build_all_embeddings_lib import (
    DEFAULT_BATCH_SIZE,
    DEFAULT_LIMIT,
    build_contextual_chunks,
    format_duration,
    get_chunks_stats,
    get_hierarchical_stats,
    process_chunks_embeddings,
    process_contextual_embeddings,
    process_hierarchical_embeddings,
)


def main() -> None:
    start_time = time.time()

    settings = load_settings()
    dsn = settings["DATABASE_URL"]

    import argparse

    parser = argparse.ArgumentParser(description="æ–¹æ¡ˆ C: å…¨é‡å‘é‡åŒ–")
    parser.add_argument("--version-id", help="æŒ‡å®šç‰ˆæœ¬ ID")
    parser.add_argument("--batch-size", type=int, default=DEFAULT_BATCH_SIZE)
    parser.add_argument("--limit", type=int, default=DEFAULT_LIMIT)
    parser.add_argument("--skip-chunks", action="store_true", help="è·³è¿‡ chunks è¡¨")
    parser.add_argument(
        "--skip-contextual", action="store_true", help="è·³è¿‡ contextual_chunks è¡¨"
    )
    parser.add_argument(
        "--skip-hierarchical", action="store_true", help="è·³è¿‡ hierarchical_nodes è¡¨"
    )
    parser.add_argument("--show-detail", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¿›åº¦")
    args = parser.parse_args()

    if not settings.get("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: OPENAI_API_KEY æœªè®¾ç½®")
        sys.exit(1)

    config = get_embedding_config()
    client = get_embedding_client()

    print("=" * 80)
    print("ğŸš€ æ–¹æ¡ˆ C: å…¨é‡å‘é‡åŒ–")
    print("=" * 80)
    print(f"æ¨¡å‹: {config['model']}")
    print(f"ç»´åº¦: {config['dim']}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    if args.version_id:
        print(f"ç‰ˆæœ¬è¿‡æ»¤: {args.version_id}")
    print()

    total_success = 0
    total_fail = 0

    with psycopg.connect(dsn) as conn:
        register_vector(conn)

        if not args.skip_chunks:
            print("=" * 80)
            print("ğŸ“¦ Step 1: chunks è¡¨åŸºç¡€å‘é‡åŒ–")
            print("=" * 80)

            stats = get_chunks_stats(conn, args.version_id)
            print(f"  æ€» chunks: {stats['total']}")
            print(f"  å·²æœ‰å‘é‡: {stats['has_count']}")
            print(f"  å¾…å¤„ç†: {stats['to_process']}")

            if stats["to_process"] > 0:
                success, fail = process_chunks_embeddings(
                    conn,
                    args.version_id,
                    args.batch_size,
                    args.limit,
                    client,
                    config["model"],
                    args.show_detail,
                )
                total_success += success
                total_fail += fail
            else:
                print("  âœ… æ— éœ€å¤„ç†")

        if not args.skip_contextual:
            print("\n" + "=" * 80)
            print("ğŸ“ Step 2: contextual_chunks è¡¨ä¸Šä¸‹æ–‡å¢å¼ºå‘é‡åŒ–")
            print("=" * 80)

            print("  æ„å»º contextual_chunks è®°å½•...")
            created = build_contextual_chunks(conn, args.version_id)
            print(f"  åˆ›å»º/æ›´æ–°: {created} æ¡")

            success, fail = process_contextual_embeddings(
                conn,
                args.version_id,
                args.batch_size,
                args.limit,
                client,
                config["model"],
                args.show_detail,
            )
            total_success += success
            total_fail += fail

        if not args.skip_hierarchical:
            print("\n" + "=" * 80)
            print("ğŸŒ² Step 3: hierarchical_nodes è¡¨å±‚æ¬¡èŠ‚ç‚¹å‘é‡åŒ–")
            print("=" * 80)

            stats = get_hierarchical_stats(conn, args.version_id)
            for level, stat in sorted(stats.items()):
                level_names = {0: "sentence", 1: "paragraph", 2: "section", 3: "document"}
                name = level_names.get(level, f"level_{level}")
                print(
                    f"  Level {level} ({name}): å¾…å¤„ç† {stat['null_count']}/{stat['total']}"
                )

            results = process_hierarchical_embeddings(
                conn,
                args.version_id,
                [1, 2],
                args.batch_size,
                args.limit,
                client,
                config["model"],
                args.show_detail,
            )

            for _level, (success, fail) in results.items():
                total_success += success
                total_fail += fail

    elapsed = time.time() - start_time

    print("\n" + "=" * 80)
    print("âœ… å¤„ç†å®Œæˆ")
    print("=" * 80)
    print(f"æ€»æˆåŠŸ: {total_success:,}")
    print(f"æ€»å¤±è´¥: {total_fail:,}")
    print(f"ç”¨æ—¶:   {format_duration(elapsed)}")
    if total_success > 0:
        print(f"å¹³å‡:   {total_success / elapsed:.1f} æ¡/ç§’")


if __name__ == "__main__":
    main()

