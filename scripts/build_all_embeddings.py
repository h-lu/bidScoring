#!/usr/bin/env python3
"""æ–¹æ¡ˆ C: å…¨é‡å‘é‡åŒ– - å¤šç²’åº¦ Embedding ç”Ÿæˆ

Features:
1. Level 1: chunks è¡¨åŸºç¡€å‘é‡åŒ– (1060æ¡)
2. Level 2: contextual_chunks è¡¨ä¸Šä¸‹æ–‡å¢å¼ºå‘é‡åŒ– (å¯é€‰)
3. Level 3: hierarchical_nodes è¡¨å±‚æ¬¡èŠ‚ç‚¹å‘é‡åŒ– (Level 1-2, éå¶å­èŠ‚ç‚¹)

æœ€ä½³å®è·µ:
- chunks: ç›´æ¥åµŒå…¥åŸå§‹æ–‡æœ¬ï¼Œç”¨äºç²¾ç¡®æ£€ç´¢
- contextual_chunks: æ·»åŠ ç« èŠ‚å‰ç¼€ï¼Œç”¨äºè¯­ä¹‰æ£€ç´¢
- hierarchical_nodes: æ®µè½/ç« èŠ‚çº§åµŒå…¥ï¼Œç”¨äºç²—ç²’åº¦æ£€ç´¢

Usage:
    python scripts/build_all_embeddings.py --version-id="xxx"
    python scripts/build_all_embeddings.py --version-id="xxx" --skip-contextual
    python scripts/build_all_embeddings.py --version-id="xxx" --skip-hierarchical
"""

import sys
import time
from datetime import datetime
from typing import Any

import psycopg
from pgvector.psycopg import register_vector
from psycopg.types.json import Jsonb

from bid_scoring.config import load_settings
from bid_scoring.embeddings import embed_texts, estimate_tokens, get_embedding_client, get_embedding_config


# é…ç½®å‚æ•°
DEFAULT_BATCH_SIZE = 100
DEFAULT_LIMIT = 10000
DEFAULT_MAX_TOKENS = 100000


def format_duration(seconds: float) -> str:
    """æ ¼å¼åŒ–æŒç»­æ—¶é—´"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        return f"{seconds/60:.1f}åˆ†é’Ÿ"
    else:
        return f"{seconds/3600:.1f}å°æ—¶"


# ============================================================================
# Level 1: chunks è¡¨åŸºç¡€å‘é‡åŒ–
# ============================================================================

def get_chunks_stats(conn, version_id: str | None = None) -> dict[str, Any]:
    """è·å– chunks è¡¨å‘é‡åŒ–ç»Ÿè®¡"""
    with conn.cursor() as cur:
        base_query = """
            SELECT 
                COUNT(*) FILTER (WHERE embedding IS NULL) as null_count,
                COUNT(*) FILTER (WHERE embedding IS NOT NULL) as has_count,
                COUNT(*) FILTER (WHERE embedding IS NULL AND text_raw IS NOT NULL AND text_raw != '') as to_process,
                COUNT(*) FILTER (WHERE embedding IS NULL AND (text_raw IS NULL OR text_raw = '')) as empty_text
            FROM chunks
        """
        
        if version_id:
            base_query += " WHERE version_id = %s"
            cur.execute(base_query, (version_id,))
        else:
            cur.execute(base_query)
        
        row = cur.fetchone()
        return {
            "null_count": row[0],
            "has_count": row[1],
            "to_process": row[2],
            "empty_text": row[3],
            "total": row[0] + row[1],
        }


def process_chunks_embeddings(
    conn,
    version_id: str | None = None,
    batch_size: int = DEFAULT_BATCH_SIZE,
    limit: int = DEFAULT_LIMIT,
    client = None,
    model: str | None = None,
    show_detail: bool = False,
) -> tuple[int, int]:
    """å¤„ç† chunks è¡¨å‘é‡åŒ–
    
    Returns:
        (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡)
    """
    stats = get_chunks_stats(conn, version_id)
    to_process = min(stats["to_process"], limit)
    
    if to_process == 0:
        print("  âœ… chunks è¡¨æ— éœ€å¤„ç†")
        return 0, 0
    
    print(f"  å¾…å¤„ç†: {to_process} æ¡")
    
    processed = 0
    success_count = 0
    fail_count = 0
    batch_num = 0
    
    while processed < to_process:
        with conn.cursor() as cur:
            # è·å–ä¸€æ‰¹æ•°æ®
            query = """
                SELECT chunk_id, text_raw
                FROM chunks 
                WHERE embedding IS NULL 
                  AND text_raw IS NOT NULL 
                  AND text_raw != ''
            """
            params = []
            if version_id:
                query += " AND version_id = %s"
                params.append(version_id)
            query += " ORDER BY chunk_id LIMIT %s"
            params.append(batch_size)
            
            cur.execute(query, params)
            rows = cur.fetchall()
            
            if not rows:
                break
            
            batch_num += 1
            ids = [str(r[0]) for r in rows]
            texts = [r[1] for r in rows]
            
            try:
                # ç”Ÿæˆå‘é‡
                vecs = embed_texts(texts, client=client, model=model, show_progress=False)
                
                # æ‰¹é‡æ›´æ–°
                update_data = [(vecs[i], ids[i]) for i in range(len(ids))]
                cur.executemany(
                    "UPDATE chunks SET embedding = %s WHERE chunk_id = %s",
                    update_data
                )
                conn.commit()
                
                success_count += len(rows)
                if show_detail:
                    print(f"    æ‰¹æ¬¡ {batch_num}: {len(rows)} æ¡ âœ…")
                
            except Exception as e:
                conn.rollback()
                fail_count += len(rows)
                print(f"    æ‰¹æ¬¡ {batch_num}: âŒ {e}")
            
            processed += len(rows)
    
    print(f"  å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
    return success_count, fail_count


# ============================================================================
# Level 2: contextual_chunks è¡¨ä¸Šä¸‹æ–‡å¢å¼ºå‘é‡åŒ–
# ============================================================================

def build_contextual_chunks(conn, version_id: str | None = None) -> int:
    """ä» chunks å’Œ hierarchical_nodes æ„å»º contextual_chunks
    
    ç­–ç•¥: ä¸ºæ¯ä¸ª chunk æ·»åŠ ä¸Šä¸‹æ–‡å‰ç¼€ï¼ˆç« èŠ‚æ ‡é¢˜ï¼‰
    
    Returns:
        åˆ›å»ºçš„ contextual_chunks æ•°é‡
    """
    with conn.cursor() as cur:
        # å…ˆæ¸…ç©ºè¯¥ç‰ˆæœ¬çš„ç°æœ‰æ•°æ®
        if version_id:
            cur.execute(
                "DELETE FROM contextual_chunks WHERE version_id = %s",
                (version_id,)
            )
        else:
            cur.execute("DELETE FROM contextual_chunks")
        
        # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„ chunks
        query = """
            SELECT 
                c.chunk_id,
                c.version_id,
                c.text_raw,
                c.page_idx,
                c.element_type
            FROM chunks c
            WHERE c.text_raw IS NOT NULL 
              AND c.text_raw != ''
        """
        params = []
        if version_id:
            query += " AND c.version_id = %s"
            params.append(version_id)
        
        cur.execute(query, params)
        chunks = cur.fetchall()
        
        if not chunks:
            return 0
        
        # ä¸ºæ¯ä¸ª chunk æŸ¥æ‰¾æ‰€å±çš„ section æ ‡é¢˜
        created_count = 0
        for chunk_id, ver_id, text_raw, page_idx, elem_type in chunks:
            # æŸ¥æ‰¾åŒ…å«æ­¤ chunk çš„ section
            cur.execute(
                """
                SELECT content, metadata
                FROM hierarchical_nodes
                WHERE version_id = %s
                  AND level = 2
                  AND (metadata->>'page_idx')::int <= %s
                ORDER BY (metadata->>'page_idx')::int DESC
                LIMIT 1
                """,
                (ver_id, page_idx or 0)
            )
            section_row = cur.fetchone()
            
            section_title = ""
            if section_row:
                section_title = section_row[0] or ""
            
            # æ„å»ºä¸Šä¸‹æ–‡å‰ç¼€
            context_prefix = ""
            if section_title:
                context_prefix = f"[{section_title}] "
            
            contextualized_text = context_prefix + text_raw
            
            # æ’å…¥ contextual_chunksï¼ˆembedding ç¨åæ›´æ–°ï¼‰
            cur.execute(
                """
                INSERT INTO contextual_chunks (
                    chunk_id, version_id, original_text, context_prefix,
                    contextualized_text, model_name, embedding_model
                ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (chunk_id) DO UPDATE SET
                    context_prefix = EXCLUDED.context_prefix,
                    contextualized_text = EXCLUDED.contextualized_text
                """,
                (
                    chunk_id, ver_id, text_raw, context_prefix,
                    contextualized_text, "text-embedding-3-small", "text-embedding-3-small"
                )
            )
            created_count += 1
        
        conn.commit()
        return created_count


def process_contextual_embeddings(
    conn,
    version_id: str | None = None,
    batch_size: int = DEFAULT_BATCH_SIZE,
    limit: int = DEFAULT_LIMIT,
    client = None,
    model: str | None = None,
    show_detail: bool = False,
) -> tuple[int, int]:
    """å¤„ç† contextual_chunks è¡¨å‘é‡åŒ–"""
    with conn.cursor() as cur:
        # è·å–ç»Ÿè®¡
        query = """
            SELECT COUNT(*) 
            FROM contextual_chunks 
            WHERE embedding IS NULL
        """
        params = []
        if version_id:
            query += " AND version_id = %s"
            params.append(version_id)
        
        cur.execute(query, params)
        to_process = cur.fetchone()[0]
        to_process = min(to_process, limit)
        
        if to_process == 0:
            print("  âœ… contextual_chunks è¡¨æ— éœ€å¤„ç†")
            return 0, 0
        
        print(f"  å¾…å¤„ç†: {to_process} æ¡")
    
    processed = 0
    success_count = 0
    fail_count = 0
    batch_num = 0
    
    while processed < to_process:
        with conn.cursor() as cur:
            query = """
                SELECT contextual_id, contextualized_text
                FROM contextual_chunks 
                WHERE embedding IS NULL
            """
            params = []
            if version_id:
                query += " AND version_id = %s"
                params.append(version_id)
            query += " ORDER BY contextual_id LIMIT %s"
            params.append(batch_size)
            
            cur.execute(query, params)
            rows = cur.fetchall()
            
            if not rows:
                break
            
            batch_num += 1
            ids = [str(r[0]) for r in rows]
            texts = [r[1] for r in rows]
            
            try:
                vecs = embed_texts(texts, client=client, model=model, show_progress=False)
                
                update_data = [(vecs[i], ids[i]) for i in range(len(ids))]
                cur.executemany(
                    "UPDATE contextual_chunks SET embedding = %s WHERE contextual_id = %s",
                    update_data
                )
                conn.commit()
                
                success_count += len(rows)
                if show_detail:
                    print(f"    æ‰¹æ¬¡ {batch_num}: {len(rows)} æ¡ âœ…")
                
            except Exception as e:
                conn.rollback()
                fail_count += len(rows)
                print(f"    æ‰¹æ¬¡ {batch_num}: âŒ {e}")
            
            processed += len(rows)
    
    print(f"  å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
    return success_count, fail_count


# ============================================================================
# Level 3: hierarchical_nodes è¡¨å±‚æ¬¡èŠ‚ç‚¹å‘é‡åŒ–
# ============================================================================

def get_hierarchical_stats(conn, version_id: str | None = None) -> dict[str, Any]:
    """è·å– hierarchical_nodes è¡¨å‘é‡åŒ–ç»Ÿè®¡"""
    with conn.cursor() as cur:
        query = """
            SELECT 
                level,
                COUNT(*) FILTER (WHERE embedding IS NULL) as null_count,
                COUNT(*) FILTER (WHERE embedding IS NOT NULL) as has_count
            FROM hierarchical_nodes
        """
        params = []
        if version_id:
            query += " WHERE version_id = %s"
            params.append(version_id)
        
        query += " GROUP BY level ORDER BY level"
        cur.execute(query, params)
        
        stats = {}
        for row in cur.fetchall():
            stats[row[0]] = {
                "null_count": row[1],
                "has_count": row[2],
                "total": row[1] + row[2],
            }
        return stats


def process_hierarchical_embeddings(
    conn,
    version_id: str | None = None,
    levels: list[int] = None,
    batch_size: int = DEFAULT_BATCH_SIZE,
    limit: int = DEFAULT_LIMIT,
    client = None,
    model: str | None = None,
    show_detail: bool = False,
) -> dict[int, tuple[int, int]]:
    """å¤„ç† hierarchical_nodes è¡¨å‘é‡åŒ–
    
    Args:
        levels: è¦å¤„ç†çš„å±‚çº§åˆ—è¡¨ï¼ˆé»˜è®¤ [1, 2]ï¼Œå³ paragraph å’Œ sectionï¼‰
    
    Returns:
        {level: (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡)}
    """
    if levels is None:
        levels = [1, 2]  # é»˜è®¤åªå¤„ç† paragraph å’Œ section
    
    level_names = {0: "sentence", 1: "paragraph", 2: "section", 3: "document"}
    results = {}
    
    for level in levels:
        level_name = level_names.get(level, f"level_{level}")
        print(f"\n  å¤„ç† Level {level} ({level_name}):")
        
        processed = 0
        success_count = 0
        fail_count = 0
        batch_num = 0
        
        while processed < limit:
            with conn.cursor() as cur:
                query = """
                    SELECT node_id, content
                    FROM hierarchical_nodes 
                    WHERE embedding IS NULL
                      AND level = %s
                """
                params = [level]
                if version_id:
                    query += " AND version_id = %s"
                    params.append(version_id)
                query += " ORDER BY node_id LIMIT %s"
                params.append(batch_size)
                
                cur.execute(query, params)
                rows = cur.fetchall()
                
                if not rows:
                    break
                
                batch_num += 1
                ids = [str(r[0]) for r in rows]
                texts = [r[1] for r in rows]
                
                try:
                    vecs = embed_texts(texts, client=client, model=model, show_progress=False)
                    
                    update_data = [(vecs[i], ids[i]) for i in range(len(ids))]
                    cur.executemany(
                        "UPDATE hierarchical_nodes SET embedding = %s WHERE node_id = %s",
                        update_data
                    )
                    conn.commit()
                    
                    success_count += len(rows)
                    if show_detail:
                        print(f"    æ‰¹æ¬¡ {batch_num}: {len(rows)} æ¡ âœ…")
                    
                except Exception as e:
                    conn.rollback()
                    fail_count += len(rows)
                    print(f"    æ‰¹æ¬¡ {batch_num}: âŒ {e}")
                
                processed += len(rows)
        
        print(f"  å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
        results[level] = (success_count, fail_count)
    
    return results


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    start_time = time.time()
    
    # åŠ è½½é…ç½®
    settings = load_settings()
    dsn = settings["DATABASE_URL"]
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description="æ–¹æ¡ˆ C: å…¨é‡å‘é‡åŒ–")
    parser.add_argument("--version-id", help="æŒ‡å®šç‰ˆæœ¬ ID")
    parser.add_argument("--batch-size", type=int, default=DEFAULT_BATCH_SIZE)
    parser.add_argument("--limit", type=int, default=DEFAULT_LIMIT)
    parser.add_argument("--skip-chunks", action="store_true", help="è·³è¿‡ chunks è¡¨")
    parser.add_argument("--skip-contextual", action="store_true", help="è·³è¿‡ contextual_chunks è¡¨")
    parser.add_argument("--skip-hierarchical", action="store_true", help="è·³è¿‡ hierarchical_nodes è¡¨")
    parser.add_argument("--show-detail", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¿›åº¦")
    args = parser.parse_args()
    
    # æ£€æŸ¥ API Key
    if not settings.get("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: OPENAI_API_KEY æœªè®¾ç½®")
        sys.exit(1)
    
    # è·å– embedding é…ç½®
    config = get_embedding_config()
    client = get_embedding_client()
    
    print("=" * 80)
    print("ğŸš€ æ–¹æ¡ˆ C: å…¨é‡å‘é‡åŒ–")
    print("=" * 80)
    print(f"æ¨¡å‹: {config['model']}")
    print(f"ç»´åº¦: {config['dim']}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    if args.version_id:
        print(f"ç‰ˆæœ¬è¿‡æ»¤: {args.version_id}")
    print()
    
    total_success = 0
    total_fail = 0
    
    # è¿æ¥æ•°æ®åº“
    with psycopg.connect(dsn) as conn:
        register_vector(conn)
        
        # ========================================================================
        # Step 1: chunks è¡¨åŸºç¡€å‘é‡åŒ–
        # ========================================================================
        if not args.skip_chunks:
            print("=" * 80)
            print("ğŸ“¦ Step 1: chunks è¡¨åŸºç¡€å‘é‡åŒ–")
            print("=" * 80)
            
            stats = get_chunks_stats(conn, args.version_id)
            print(f"  æ€» chunks: {stats['total']}")
            print(f"  å·²æœ‰å‘é‡: {stats['has_count']}")
            print(f"  å¾…å¤„ç†: {stats['to_process']}")
            
            if stats["to_process"] > 0:
                success, fail = process_chunks_embeddings(
                    conn, args.version_id, args.batch_size, args.limit,
                    client, config["model"], args.show_detail
                )
                total_success += success
                total_fail += fail
            else:
                print("  âœ… æ— éœ€å¤„ç†")
        
        # ========================================================================
        # Step 2: contextual_chunks è¡¨ä¸Šä¸‹æ–‡å¢å¼ºå‘é‡åŒ–
        # ========================================================================
        if not args.skip_contextual:
            print("\n" + "=" * 80)
            print("ğŸ“ Step 2: contextual_chunks è¡¨ä¸Šä¸‹æ–‡å¢å¼ºå‘é‡åŒ–")
            print("=" * 80)
            
            # å…ˆæ„å»º contextual_chunks è®°å½•
            print("  æ„å»º contextual_chunks è®°å½•...")
            created = build_contextual_chunks(conn, args.version_id)
            print(f"  åˆ›å»º/æ›´æ–°: {created} æ¡")
            
            # ç„¶åç”Ÿæˆå‘é‡
            success, fail = process_contextual_embeddings(
                conn, args.version_id, args.batch_size, args.limit,
                client, config["model"], args.show_detail
            )
            total_success += success
            total_fail += fail
        
        # ========================================================================
        # Step 3: hierarchical_nodes è¡¨å±‚æ¬¡èŠ‚ç‚¹å‘é‡åŒ–
        # ========================================================================
        if not args.skip_hierarchical:
            print("\n" + "=" * 80)
            print("ğŸŒ² Step 3: hierarchical_nodes è¡¨å±‚æ¬¡èŠ‚ç‚¹å‘é‡åŒ–")
            print("=" * 80)
            
            stats = get_hierarchical_stats(conn, args.version_id)
            for level, stat in sorted(stats.items()):
                level_names = {0: "sentence", 1: "paragraph", 2: "section", 3: "document"}
                name = level_names.get(level, f"level_{level}")
                print(f"  Level {level} ({name}): å¾…å¤„ç† {stat['null_count']}/{stat['total']}")
            
            results = process_hierarchical_embeddings(
                conn, args.version_id, [1, 2],  # åªå¤„ç† paragraph å’Œ section
                args.batch_size, args.limit,
                client, config["model"], args.show_detail
            )
            
            for level, (success, fail) in results.items():
                total_success += success
                total_fail += fail
    
    # æœ€ç»ˆç»Ÿè®¡
    elapsed = time.time() - start_time
    
    print("\n" + "=" * 80)
    print("âœ… å¤„ç†å®Œæˆ")
    print("=" * 80)
    print(f"æ€»æˆåŠŸ: {total_success:,}")
    print(f"æ€»å¤±è´¥: {total_fail:,}")
    print(f"ç”¨æ—¶:   {format_duration(elapsed)}")
    if total_success > 0:
        print(f"å¹³å‡:   {total_success/elapsed:.1f} æ¡/ç§’")


if __name__ == "__main__":
    main()
