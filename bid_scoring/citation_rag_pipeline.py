"""
Citation-Aware RAG Pipeline with Precise Source Tracking
=======================================================

æä¾›ç²¾ç¡®ä½ç½®è¿½è¸ªå’Œ PDF é«˜äº®æ”¯æŒçš„ RAG Pipelineã€‚

ç‰¹æ€§:
- ç­”æ¡ˆå¼•ç”¨è‡ªåŠ¨ç”Ÿæˆ [citation:CHUNK_ID]
- ç²¾ç¡®ä½ç½®è¿½è¸ª (page_idx + bbox)
- PDF é«˜äº®å…¼å®¹çš„è¾“å‡ºæ ¼å¼
- æ”¯æŒ Small-to-Big æ£€ç´¢ç­–ç•¥

Usage:
    pipeline = CitationRAGPipeline(version_id="xxx")
    result = pipeline.query("å”®åæœåŠ¡åŒ…æ‹¬å“ªäº›å†…å®¹ï¼Ÿ")
    # result.highlight_boxes å¯ç”¨äº PDF é«˜äº®
"""

import re
import json
import psycopg
from dataclasses import dataclass, field, asdict
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime

from bid_scoring.config import load_settings
from bid_scoring.embeddings import embed_single_text
from bid_scoring.llm import LLMClient


@dataclass
class BoundingBox:
    """PDF è¾¹ç•Œæ¡†åæ ‡ (PDF åæ ‡ç³»)"""
    x1: float  # å·¦ä¸Šè§’ x
    y1: float  # å·¦ä¸Šè§’ y
    x2: float  # å³ä¸‹è§’ x
    y2: float  # å³ä¸‹è§’ y
    
    def to_dict(self) -> Dict[str, float]:
        return {"x1": self.x1, "y1": self.y1, "x2": self.x2, "y2": self.y2}
    
    @classmethod
    def from_list(cls, bbox_list: List[float]) -> "BoundingBox":
        if len(bbox_list) >= 4:
            return cls(x1=bbox_list[0], y1=bbox_list[1], x2=bbox_list[2], y2=bbox_list[3])
        return cls(x1=0, y1=0, x2=0, y2=0)


@dataclass
class HighlightBox:
    """PDF é«˜äº®æ¡†ä¿¡æ¯"""
    chunk_id: str           # å…³è”çš„ chunk ID
    page_idx: int          # PDF é¡µç  (ä» 0 å¼€å§‹)
    bbox: BoundingBox      # è¾¹ç•Œæ¡†åæ ‡
    text_preview: str      # æ–‡æœ¬é¢„è§ˆ
    color: str = "yellow"  # é«˜äº®é¢œè‰²
    
    # MinerU åŸå§‹åæ ‡ (0-1000 èŒƒå›´)
    raw_bbox: Optional[List[float]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "chunk_id": self.chunk_id,
            "page_idx": self.page_idx,
            "bbox": self.bbox.to_dict(),
            "text_preview": self.text_preview[:100] if self.text_preview else "",
            "color": self.color,
            "raw_bbox": self.raw_bbox
        }
    
    def get_pdf_bbox(self, page_width: float, page_height: float) -> BoundingBox:
        """
        å°† MinerU åæ ‡ (0-1000) è½¬æ¢ä¸º PDF ç‚¹åæ ‡
        
        MinerU çš„ bbox å­˜å‚¨åœ¨æ•°æ®åº“ä¸­æ˜¯ 0-1000 èŒƒå›´çš„å½’ä¸€åŒ–åæ ‡ï¼Œ
        éœ€è¦è½¬æ¢ä¸ºå®é™…çš„ PDF ç‚¹åæ ‡æ‰èƒ½æ­£ç¡®é«˜äº®ã€‚
        """
        if self.raw_bbox and len(self.raw_bbox) >= 4:
            x1 = self.raw_bbox[0] * (page_width / 1000)
            y1 = self.raw_bbox[1] * (page_height / 1000)
            x2 = self.raw_bbox[2] * (page_width / 1000)
            y2 = self.raw_bbox[3] * (page_height / 1000)
            return BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2)
        return self.bbox


@dataclass
class SourceSpan:
    """æºæ–‡æœ¬è·¨åº¦ä¿¡æ¯ (ç”¨äºç²¾ç¡®å¼•ç”¨)"""
    chunk_id: str
    source_chunk_id: str   # åŸå§‹ MinerU chunk_id
    text: str
    page_idx: int
    bbox: BoundingBox


@dataclass
class CitationContext:
    """å¸¦å¼•ç”¨ä¿¡æ¯çš„ä¸Šä¸‹æ–‡ (å¯¹åº” section çº§åˆ«)"""
    section_id: str
    heading: str
    content: str
    similarity: float
    
    # æº¯æºä¿¡æ¯
    source_chunk_ids: List[str] = field(default_factory=list)
    page_range: Optional[Tuple[int, int]] = None
    
    # ç²¾ç¡®ä½ç½® (åŸå§‹ chunks)
    source_spans: List[SourceSpan] = field(default_factory=list)
    
    def to_prompt_format(self, index: int) -> str:
        """è½¬æ¢ä¸º Prompt ä¸­çš„å¼•ç”¨æ ¼å¼"""
        return f"""
[{index}] ID: {self.section_id}
æ ‡é¢˜: {self.heading or 'æ— æ ‡é¢˜'}
å†…å®¹: {self.content[:800]}{'...' if len(self.content) > 800 else ''}
""".strip()


@dataclass
class Citation:
    """å•ä¸ªå¼•ç”¨ä¿¡æ¯"""
    citation_id: str       # å¼•ç”¨æ ‡è®°ï¼Œå¦‚ "[1]"
    section_id: str        # å¼•ç”¨çš„ section ID
    section_heading: str   # section æ ‡é¢˜
    text: str             # å¼•ç”¨çš„æ–‡æœ¬ç‰‡æ®µ
    highlight_boxes: List[HighlightBox] = field(default_factory=list)


@dataclass
class CitedAnswer:
    """å¸¦å¼•ç”¨çš„ç­”æ¡ˆ (æœ€ç»ˆè¾“å‡º)"""
    answer: str
    citations: List[Citation]
    highlight_boxes: List[HighlightBox]
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸ (ç”¨äº API è¿”å›)"""
        return {
            "answer": self.answer,
            "citations": [
                {
                    "citation_id": c.citation_id,
                    "section_id": c.section_id,
                    "section_heading": c.section_heading,
                    "text": c.text[:200] if c.text else "",
                    "highlight_boxes": [h.to_dict() for h in c.highlight_boxes]
                }
                for c in self.citations
            ],
            "highlight_boxes": [h.to_dict() for h in self.highlight_boxes],
            "metadata": self.metadata
        }
    
    def to_json(self, indent: int = 2) -> str:
        """è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=indent, default=str)


class CitationRetriever:
    """å¸¦ç²¾ç¡®ä½ç½®è¿½è¸ªçš„æ£€ç´¢å™¨"""
    
    def __init__(self, version_id: str, top_k: int = 5):
        self.version_id = version_id
        self.top_k = top_k
    
    def _get_db_connection(self):
        settings = load_settings()
        return psycopg.connect(settings["DATABASE_URL"])
    
    def _fetch_chunk_spans(
        self, 
        chunk_node_ids: List[str],
        node_contents: Dict[str, str] = None
    ) -> List[SourceSpan]:
        """
        æ ¹æ® hierarchical_nodes çš„ chunk node IDs è·å–å¯¹åº”çš„ chunks è¡¨ä½ç½®ä¿¡æ¯
        
        ç­–ç•¥: ä½¿ç”¨ page_range æŸ¥è¯¢å¯¹åº”é¡µé¢çš„ chunks
        """
        if not chunk_node_ids:
            return []
        
        conn = self._get_db_connection()
        spans = []
        seen_chunk_ids = set()
        
        try:
            with conn.cursor() as cur:
                # è·å–è¿™äº› chunk nodes çš„ page_range
                placeholders = ','.join(['%s'] * len(chunk_node_ids))
                cur.execute(f"""
                    SELECT node_id, page_range, content_for_embedding
                    FROM hierarchical_nodes
                    WHERE node_id IN ({placeholders})
                      AND level = 2
                """, tuple(chunk_node_ids))
                
                node_infos = {}
                for row in cur.fetchall():
                    node_id = str(row[0])
                    page_range = row[1]
                    content = row[2]
                    node_infos[node_id] = (page_range, content)
                
                # å¯¹æ¯ä¸ª chunk nodeï¼ŒæŸ¥è¯¢å¯¹åº”é¡µé¢çš„ chunks
                for node_id, (page_range, node_content) in node_infos.items():
                    if not page_range or len(page_range) < 2:
                        continue
                    
                    start_page, end_page = page_range[0], page_range[1]
                    
                    # æŸ¥è¯¢è¯¥é¡µé¢çš„å‰ 5 ä¸ª chunksï¼ˆæŒ‰ä½ç½®æ’åºï¼‰
                    cur.execute("""
                        SELECT chunk_id, chunk_index, page_idx, bbox, text_raw
                        FROM chunks
                        WHERE version_id = %s
                          AND page_idx >= %s 
                          AND page_idx <= %s
                          AND bbox IS NOT NULL
                          AND text_raw IS NOT NULL
                        ORDER BY chunk_index
                        LIMIT 5
                    """, (self.version_id, start_page, end_page))
                    
                    for row in cur.fetchall():
                        chunk_id = str(row[0])
                        if chunk_id in seen_chunk_ids:
                            continue
                        seen_chunk_ids.add(chunk_id)
                        
                        chunk_index, page_idx, bbox_json, text_raw = row[1], row[2], row[3], row[4]
                        
                        # è§£æ bbox
                        bbox = BoundingBox.from_list(bbox_json) if bbox_json else BoundingBox(0, 0, 0, 0)
                        
                        spans.append(SourceSpan(
                            chunk_id=chunk_id,
                            source_chunk_id=chunk_id,
                            text=text_raw or "",
                            page_idx=page_idx or 0,
                            bbox=bbox
                        ))
        finally:
            conn.close()
        
        return spans
    
    def retrieve(self, query: str) -> List[CitationContext]:
        """
        æ£€ç´¢ç›¸å…³ sectionï¼Œå¹¶è·å–ç²¾ç¡®ä½ç½®ä¿¡æ¯
        
        æµç¨‹:
        1. åµŒå…¥ query
        2. æœç´¢æœ€ç›¸ä¼¼çš„ chunks (leaf nodes)
        3. JOIN è·å– parent sections
        4. ä¸ºæ¯ä¸ª section è·å–åŸå§‹ chunk çš„ä½ç½®ä¿¡æ¯ (åŸºäºæ–‡æœ¬ç›¸ä¼¼åº¦åŒ¹é…)
        """
        # 1. åµŒå…¥ query
        query_embedding = embed_single_text(query)
        
        conn = self._get_db_connection()
        contexts = []
        
        try:
            with conn.cursor() as cur:
                # 2. æœç´¢æœ€ç›¸ä¼¼çš„ chunksï¼Œå¹¶ JOIN è·å– parent sections
                cur.execute("""
                    WITH ranked_chunks AS (
                        SELECT 
                            c.node_id as chunk_id,
                            c.parent_id,
                            c.heading,
                            c.content,
                            c.content_for_embedding,
                            c.source_chunk_ids,
                            c.page_range,
                            1 - (c.embedding <=> %s::vector) as similarity
                        FROM hierarchical_nodes c
                        WHERE c.version_id = %s
                            AND c.level = 2  -- leaf nodes (chunks)
                            AND c.embedding IS NOT NULL
                        ORDER BY c.embedding <=> %s::vector
                        LIMIT %s
                    )
                    SELECT DISTINCT ON (rc.parent_id)
                        s.node_id as section_id,
                        s.heading as section_heading,
                        s.content as section_content,
                        s.source_chunk_ids,
                        s.page_range,
                        rc.chunk_id as matched_chunk_id,  -- åŒ¹é…çš„ chunk node ID
                        rc.similarity
                    FROM ranked_chunks rc
                    JOIN hierarchical_nodes s ON rc.parent_id = s.node_id
                    WHERE s.level = 1  -- sections
                    ORDER BY rc.parent_id, rc.similarity DESC
                    LIMIT %s
                """, (query_embedding, self.version_id, 
                      query_embedding, self.top_k * 2, self.top_k))
                
                for row in cur.fetchall():
                    section_id, heading, content, source_chunk_ids, page_range, matched_chunk_id, similarity = row
                    
                    # è§£æ source_chunk_ids å’Œ page_range
                    chunk_id_list = [str(cid) for cid in source_chunk_ids] if source_chunk_ids else []
                    page_range_tuple = tuple(page_range) if page_range else None
                    
                    # è·å–ç²¾ç¡®ä½ç½®ä¿¡æ¯ (åŸºäºåŒ¹é…çš„ chunk node)
                    # æ”¶é›†è¯¥ section ä¸‹æ‰€æœ‰åŒ¹é…çš„ chunk nodes
                    source_spans = self._fetch_chunk_spans([str(matched_chunk_id)])
                    
                    context = CitationContext(
                        section_id=str(section_id),
                        heading=heading or "æœªå‘½åç« èŠ‚",
                        content=content or "",
                        similarity=float(similarity),
                        source_chunk_ids=chunk_id_list,
                        page_range=page_range_tuple,
                        source_spans=source_spans
                    )
                    contexts.append(context)
        finally:
            conn.close()
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        contexts.sort(key=lambda x: x.similarity, reverse=True)
        return contexts[:self.top_k]


class CitationRAGPipeline:
    """
    å¸¦ç²¾ç¡®ä½ç½®è¿½è¸ªçš„ RAG Pipeline
    
    ç‰¹ç‚¹:
    - LLM ç”Ÿæˆå¸¦ [citation:ID] æ ‡è®°çš„ç­”æ¡ˆ
    - è‡ªåŠ¨æå–å¼•ç”¨å¹¶ç”Ÿæˆé«˜äº®æ¡†
    - æ”¯æŒ PDF åæ ‡çº§åˆ«çš„é«˜äº®
    """
    
    # Citation-Aware System Prompt
    CITATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸“ä¸šçš„æŠ•æ ‡åˆ†æåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ã€‚

é‡è¦è§„åˆ™:
1. **æ¯ä¸ªäº‹å®æ€§é™ˆè¿°éƒ½å¿…é¡»æ ‡æ³¨å¼•ç”¨**ï¼Œæ ¼å¼: [citation:ID]
   - ID æ˜¯å‚è€ƒèµ„æ–™ä¸­æ ‡è®°çš„ç¼–å·ï¼Œå¦‚ [1], [2] ç­‰
   - å¼•ç”¨åº”ç´§è·Ÿåœ¨ç›¸å…³é™ˆè¿°ä¹‹å
2. åªä½¿ç”¨æä¾›çš„å‚è€ƒèµ„æ–™ï¼Œç¦æ­¢å¼•å…¥å¤–éƒ¨çŸ¥è¯†
3. å¦‚æœæ— æ³•ä»èµ„æ–™ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè¯´æ˜"æ ¹æ®ç°æœ‰èµ„æ–™æ— æ³•å›ç­”"
4. ä¿æŒå›ç­”ç®€æ´å‡†ç¡®ï¼Œä¼˜å…ˆå¼•ç”¨ç›¸ä¼¼åº¦é«˜çš„èµ„æ–™

å¼•ç”¨æ ¼å¼ç¤ºä¾‹:
- å”®åæœåŠ¡çƒ­çº¿æ˜¯ 400-650-6632 [citation:1]
- è´¨ä¿æœŸä¸ºè‡ªéªŒæ”¶åˆæ ¼ä¹‹æ—¥èµ· 5 å¹´ [citation:2][citation:3]

å‚è€ƒèµ„æ–™æŒ‰ç›¸ä¼¼åº¦ä»é«˜åˆ°ä½æ’åˆ—ã€‚"""

    def __init__(self, version_id: str, top_k: int = 5):
        self.version_id = version_id
        self.retriever = CitationRetriever(version_id, top_k=top_k)
        
        # ç”¨äºåŒ¹é…å¼•ç”¨æ ‡è®°çš„æ­£åˆ™
        self.citation_pattern = re.compile(r'\[citation:(\d+)\]')
    
    def _build_user_prompt(self, query: str, contexts: List[CitationContext]) -> str:
        """æ„å»ºå¸¦å¼•ç”¨çš„ User Prompt"""
        contexts_text = "\n\n".join(
            ctx.to_prompt_format(i + 1) 
            for i, ctx in enumerate(contexts)
        )
        
        return f"""
å‚è€ƒèµ„æ–™:
{contexts_text}

é—®é¢˜: {query}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶åœ¨æ¯ä¸ªäº‹å®æ€§é™ˆè¿°åæ ‡æ³¨å¼•ç”¨ [citation:ID]ã€‚"""
    
    def _extract_citations(self, answer: str, contexts: List[CitationContext]) -> List[Citation]:
        """
        ä»ç­”æ¡ˆä¸­æå–å¼•ç”¨æ ‡è®°ï¼Œå¹¶ç”Ÿæˆ Citation å¯¹è±¡
        
        åŒ¹é… [citation:1] -> å¯¹åº” contexts[0]
        """
        citations = []
        seen_ids = set()
        
        for match in self.citation_pattern.finditer(answer):
            citation_num = int(match.group(1))
            citation_id = match.group(0)  # [citation:1]
            
            if citation_num < 1 or citation_num > len(contexts):
                continue
            if citation_id in seen_ids:
                continue
            
            seen_ids.add(citation_id)
            context = contexts[citation_num - 1]
            
            # ä¸ºæ¯ä¸ª source_span ç”Ÿæˆ highlight box
            highlight_boxes = []
            for span in context.source_spans:
                # å­˜å‚¨åŸå§‹ bbox (MinerU 0-1000 æ ¼å¼) ç”¨äºåç»­ PDF åæ ‡è½¬æ¢
                raw_bbox = [span.bbox.x1, span.bbox.y1, span.bbox.x2, span.bbox.y2]
                highlight_boxes.append(HighlightBox(
                    chunk_id=span.chunk_id,
                    page_idx=span.page_idx,
                    bbox=span.bbox,
                    text_preview=span.text[:100],
                    color="yellow",
                    raw_bbox=raw_bbox
                ))
            
            citation = Citation(
                citation_id=citation_id,
                section_id=context.section_id,
                section_heading=context.heading,
                text=context.content[:300],
                highlight_boxes=highlight_boxes
            )
            citations.append(citation)
        
        return citations
    
    def _build_highlight_boxes(self, citations: List[Citation]) -> List[HighlightBox]:
        """æ”¶é›†æ‰€æœ‰é«˜äº®æ¡† (å»é‡)"""
        seen_chunks = set()
        boxes = []
        
        for citation in citations:
            for box in citation.highlight_boxes:
                if box.chunk_id not in seen_chunks:
                    seen_chunks.add(box.chunk_id)
                    boxes.append(box)
        
        # æŒ‰é¡µç æ’åº
        boxes.sort(key=lambda x: (x.page_idx, x.bbox.y1))
        return boxes
    
    def query(self, query: str, temperature: float = 0.3) -> CitedAnswer:
        """
        æ‰§è¡Œå¸¦ç²¾ç¡®ä½ç½®è¿½è¸ªçš„ RAG æŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            temperature: LLM æ¸©åº¦å‚æ•°
        
        Returns:
            CitedAnswer: åŒ…å«ç­”æ¡ˆã€å¼•ç”¨å’Œé«˜äº®æ¡†
        """
        # 1. æ£€ç´¢ç›¸å…³ section
        contexts = self.retriever.retrieve(query)
        
        if not contexts:
            return CitedAnswer(
                answer="æ ¹æ®ç°æœ‰èµ„æ–™æ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚",
                citations=[],
                highlight_boxes=[],
                metadata={"query": query, "retrieved_count": 0}
            )
        
        # 2. æ„å»º Prompt
        system_prompt = self.CITATION_SYSTEM_PROMPT
        user_prompt = self._build_user_prompt(query, contexts)
        
        # 3. è°ƒç”¨ LLM
        llm_client = LLMClient(load_settings())
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        raw_answer = llm_client.complete(
            messages=messages,
            temperature=temperature
        )
        
        # 4. æå–å¼•ç”¨
        citations = self._extract_citations(raw_answer, contexts)
        
        # 5. ç”Ÿæˆé«˜äº®æ¡†
        highlight_boxes = self._build_highlight_boxes(citations)
        
        return CitedAnswer(
            answer=raw_answer,
            citations=citations,
            highlight_boxes=highlight_boxes,
            metadata={
                "query": query,
                "retrieved_count": len(contexts),
                "citation_count": len(citations),
                "highlight_count": len(highlight_boxes),
                "version_id": self.version_id,
                "timestamp": datetime.now().isoformat()
            }
        )


# ä¾¿æ·å‡½æ•°
def query_with_citations(version_id: str, query: str, top_k: int = 5) -> CitedAnswer:
    """ä¾¿æ·å‡½æ•°ï¼šæ‰§è¡Œå¸¦å¼•ç”¨çš„ RAG æŸ¥è¯¢"""
    pipeline = CitationRAGPipeline(version_id=version_id, top_k=top_k)
    return pipeline.query(query)


if __name__ == "__main__":
    # æµ‹è¯•
    import os
    from dotenv import load_dotenv
    load_dotenv(override=True)
    
    VERSION_ID = "9a5a0214-3b98-4a64-9194-a01648479f7a"
    
    print("ğŸ§ª æµ‹è¯• Citation-Aware RAG Pipeline")
    print("=" * 50)
    
    pipeline = CitationRAGPipeline(version_id=VERSION_ID, top_k=3)
    
    test_queries = [
        "å”®åæœåŠ¡åŒ…æ‹¬å“ªäº›å†…å®¹ï¼Ÿ",
        "è´¨ä¿æœŸæ˜¯å¤šé•¿æ—¶é—´ï¼Ÿ",
        "åŸ¹è®­å†…å®¹åŒ…æ‹¬å“ªäº›ï¼Ÿ"
    ]
    
    for query in test_queries[:1]:  # å…ˆæµ‹è¯•ç¬¬ä¸€ä¸ª
        print(f"\nâ“ é—®é¢˜: {query}")
        print("-" * 50)
        
        result = pipeline.query(query)
        
        print(f"\nğŸ’¡ ç­”æ¡ˆ:\n{result.answer}")
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"  - æ£€ç´¢åˆ° {result.metadata['retrieved_count']} ä¸ª sections")
        print(f"  - ç”Ÿæˆ {result.metadata['citation_count']} ä¸ªå¼•ç”¨")
        print(f"  - å¯é«˜äº® {len(result.highlight_boxes)} ä¸ªåŒºåŸŸ")
        
        if result.highlight_boxes:
            print(f"\nğŸ“ é«˜äº®æ¡†é¢„è§ˆ (å‰ 3 ä¸ª):")
            for box in result.highlight_boxes[:3]:
                print(f"  é¡µ {box.page_idx}: bbox={box.bbox.to_dict()}, text={box.text_preview[:40]}...")
        
        print(f"\nğŸ“‹ JSON è¾“å‡ºé¢„è§ˆ:")
        print(result.to_json()[:800] + "...")
