# v0.2 Data Layer (Traceable Evidence) Implementation Plan

> **For Codex:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Upgrade the v0.1 data layer so citations can be verified against stable, normalized `content_units` (unit + anchor + span), while keeping `chunks/*` as rebuildable index layers.

**Architecture:** Introduce a normalized layer (`document_pages`, `content_units`) and a mapping layer (`chunk_unit_spans`). Keep `chunks/contextual_chunks/hierarchical_nodes` as rebuildable indexes. Extend `citations` to reference `unit_id + quote_span (+ evidence_hash)`; keep `chunk_id` only as an optional retrieval provenance.

**Tech Stack:** PostgreSQL (pgcrypto, pgvector), psycopg3, Python, uv, pytest.

---

### Task 1: Define v0.2 Anchor + Hash Utilities

**Files:**
- Create: `bid_scoring/anchors_v2.py`
- Test: `tests/test_anchors_v2.py`

**Step 1: Write failing tests**

Create `tests/test_anchors_v2.py`:

```python
from bid_scoring.anchors_v2 import build_anchor_json, normalize_text, compute_unit_hash


def test_build_anchor_json_shape():
    anchor = build_anchor_json(
        anchors=[
            {
                "page_idx": 12,
                "bbox": [100, 200, 300, 240],
                "coord_sys": "mineru_bbox_v1",
                "page_w": None,
                "page_h": None,
                "path": None,
                "source": {"element_id": "chunk_0000"},
            }
        ]
    )
    assert "anchors" in anchor
    assert anchor["anchors"][0]["page_idx"] == 12


def test_compute_unit_hash_is_stable():
    text_norm = normalize_text("A  B")
    anchor = build_anchor_json(
        anchors=[
            {
                "page_idx": 1,
                "bbox": [1, 2, 3, 4],
                "coord_sys": "mineru_bbox_v1",
                "page_w": None,
                "page_h": None,
                "path": None,
                "source": {"element_id": "x"},
            }
        ]
    )
    h1 = compute_unit_hash(text_norm=text_norm, anchor_json=anchor, source_element_id="x")
    h2 = compute_unit_hash(text_norm=text_norm, anchor_json=anchor, source_element_id="x")
    assert h1 == h2
```

**Step 2: Run tests to verify RED**

Run: `uv run pytest -q tests/test_anchors_v2.py`
Expected: FAIL (module `bid_scoring.anchors_v2` missing).

**Step 3: Implement minimal utilities**

Create `bid_scoring/anchors_v2.py`:
- `build_anchor_json(anchors: list[dict]) -> dict`
- `normalize_text(text: str) -> str` (collapse whitespace; safe for hashing)
- `canonical_json(obj) -> str` (stable JSON encoding with sorted keys)
- `compute_unit_hash(text_norm: str, anchor_json: dict, source_element_id: str | None) -> str` (sha256)

**Step 4: Run tests to verify GREEN**

Run: `uv run pytest -q tests/test_anchors_v2.py`
Expected: PASS.

**Step 5: Commit**

```bash
git add bid_scoring/anchors_v2.py tests/test_anchors_v2.py
git commit -m "feat(data): add anchor schema + unit hash helpers"
```

---

### Task 2: Add v0.2 Tables and Citation Columns to Schema

**Files:**
- Modify: `migrations/000_init.sql`
- Modify: `tests/test_db_schema.py`

**Step 1: Write failing test (tables list)**

Update `tests/test_db_schema.py` expected tables:
- Add: `document_pages`, `content_units`, `chunk_unit_spans`

**Step 2: Run tests to verify RED**

Run: `uv run pytest -q tests/test_db_schema.py::test_tables_exist`
Expected: FAIL (new tables missing).

**Step 3: Update schema**

Modify `migrations/000_init.sql`:
- Add `document_pages` (keyed by `version_id + page_idx`)
- Add `content_units` with constraints:
  - `UNIQUE(version_id, unit_index)`
  - `UNIQUE(version_id, source_element_id)` (ok with NULLs)
- Add `chunk_unit_spans` with constraints:
  - `PRIMARY KEY(chunk_id, unit_id)`
  - `UNIQUE(chunk_id, unit_order)`
- Extend `citations` via `ALTER TABLE ... ADD COLUMN IF NOT EXISTS`:
  - `unit_id UUID REFERENCES content_units(unit_id)`
  - `quote_text TEXT`
  - `quote_start_char INT`
  - `quote_end_char INT`
  - `anchor_json JSONB`
  - `evidence_hash TEXT`

**Step 4: Run tests to verify GREEN**

Run: `uv run pytest -q tests/test_db_schema.py::test_tables_exist`
Expected: PASS.

**Step 5: Commit**

```bash
git add migrations/000_init.sql tests/test_db_schema.py
git commit -m "feat(db): add v0.2 normalized units + spans tables"
```

---

### Task 3: Ingestion Writes Units First, Then Chunks (Index), Then Spans

**Files:**
- Modify: `bid_scoring/ingest.py`
- Test: `tests/test_ingest_v2_units.py`

**Step 1: Write failing test**

Create `tests/test_ingest_v2_units.py`:
- Run `ingest_content_list(...)`
- Assert:
  - `content_units` rowcount > 0
  - `chunk_unit_spans` rowcount equals inserted chunks (for 1:1 strategy)
  - `content_units.anchor_json` contains `anchors[0].page_idx` and bbox

**Step 2: Run tests to verify RED**

Run: `uv run pytest -q tests/test_ingest_v2_units.py`
Expected: FAIL (tables empty / insert missing).

**Step 3: Implement ingestion changes**

In `bid_scoring/ingest.py`:
- Keep skip rules (page_number/header/footer).
- Insert `document_pages` entries for pages observed in units (with NULL `page_w/h` for now).
- Upsert `content_units` using `(version_id, unit_index)` conflict target; preserve existing `unit_id`.
- Delete and rebuild `chunks` for the version (current behavior) and insert 1:1 chunks from units.
- Populate `chunk_unit_spans` mapping each inserted chunk to its unit with `unit_order=0` and full-span chars.

**Step 4: Run tests to verify GREEN**

Run: `uv run pytest -q tests/test_ingest.py tests/test_ingest_v2_units.py`
Expected: PASS.

**Step 5: Commit**

```bash
git add bid_scoring/ingest.py tests/test_ingest_v2_units.py
git commit -m "feat(ingest): persist v0.2 content_units + chunk_unit_spans"
```

---

### Task 4: Retrieval Can Return Unit Evidence (Unit + Anchor + Span)

**Files:**
- Modify: `bid_scoring/hybrid_retrieval.py`
- Test: `tests/test_retrieval_evidence_v2.py`

**Step 1: Write failing test**

Create `tests/test_retrieval_evidence_v2.py`:
- Insert 1 version via `ingest_content_list`
- Query DB for two `chunk_id`s
- Call `HybridRetriever(...)._fetch_chunks(...)` (internal) with those IDs
- Assert result items include `evidence_units` populated with `unit_id` and `anchor_json`

**Step 2: Run tests to verify RED**

Run: `uv run pytest -q tests/test_retrieval_evidence_v2.py`
Expected: FAIL (no evidence attached).

**Step 3: Implement evidence attach**

In `bid_scoring/hybrid_retrieval.py`:
- Add `EvidenceUnit` dataclass (unit_id, unit_index, unit_type, text, anchor_json, start_char, end_char, unit_order)
- Extend `RetrievalResult` with `evidence_units: list[EvidenceUnit] = field(default_factory=list)`
- In `_fetch_chunks`, fetch spans for selected chunks and attach evidence_units.

**Step 4: Run tests to verify GREEN**

Run: `uv run pytest -q tests/test_retrieval_evidence_v2.py`
Expected: PASS.

**Step 5: Commit**

```bash
git add bid_scoring/hybrid_retrieval.py tests/test_retrieval_evidence_v2.py
git commit -m "feat(retrieval): attach unit-level evidence to results"
```

---

### Task 5 (Optional P0 Backfill): Backfill Units From Existing Chunks

**Files:**
- Create: `scripts/backfill_v0_2_units.py`

**Steps:**
1. Add a script that reads `chunks` for a `version_id` (or all versions) and upserts:
   - `document_pages` from `chunks.page_idx`
   - `content_units` from `chunks.(chunk_index, element_type, text_raw, page_idx, bbox, source_id)`
   - `chunk_unit_spans` 1:1 mapping
2. Provide dry-run and idempotent behavior.
3. Manual verification:
   - Run backfill twice; rowcounts should not grow on second run.

